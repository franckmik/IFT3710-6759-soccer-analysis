{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eca6c2-1166-434c-82da-504407b327e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafe4f0-9fd8-4eff-8068-f671e845a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_data\n",
    "from vae import VAE\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc92fd-5b10-43a4-a6a7-eddbfd95788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les images et les labels\n",
    "images, labels = [], []\n",
    "\n",
    "events = [#'cards', \n",
    "          #'center'\n",
    "          #'free-kick'\n",
    "          #'cards',\n",
    "          'To Subtitue'\n",
    "         ]\n",
    "\n",
    "train_images, train_labels = get_data(folder='train', events=events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62810e-9da8-47a2-bf7d-bd9fa0eb1002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from vae import recon_loss, vae_loss\n",
    "\n",
    "train_dataset = train_images\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialisation du modèle, de l'optimiseur et des paramètres\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae_instance = VAE().to(device)\n",
    "optimizer = optim.Adam(vae_instance.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 30\n",
    "vae_instance.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for imgs in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_imgs, mu, logvar = vae_instance(imgs)\n",
    "        loss = vae_loss(recon_imgs, imgs, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_dataset):.4f}\")\n",
    "\n",
    "# entrainer sur 100 epoques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb26f2d-2e4d-4110-bb3a-1cd1e9938553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold VAE loss: the value of 328 as the threshold for the loss gives the best distinction between categories\n",
    "\n",
    "# the images of seven events(corner ok, penalty ok, free kick ok, red card, yellow card, tackle ok, substitute) defined from \n",
    "# the SEV dataset are selected and given to the VAE\n",
    "# network as training data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
